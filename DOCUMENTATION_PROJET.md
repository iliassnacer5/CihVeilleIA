# üìò Documentation Technique - Projet CIH-Veille-IA

Ce document pr√©sente une analyse technique d√©taill√©e, l'architecture, et le fonctionnement de la plateforme de veille intelligente **CIH-Veille-IA**.

---

## üèóÔ∏è 1. Architecture Globale & Technologies

### 1.1 Vue d'Ensemble
La plateforme est con√ßue comme un syst√®me modulaire de veille strat√©gique bancaire int√©grant :
- **Backend API (FastAPI)** : G√®re la logique m√©tier, l'authentification, les websockets et l'exposition des donn√©es.
- **Micro-services IA (Interne)** : 
  - **Scraping** : Collecte intelligente (Institutional + Browser based).
  - **NLP** : Traitement du langage naturel (Classification, NER, R√©sum√©).
  - **RAG (Retrieval Augmented Generation)** : Moteur de recherche s√©mantique et Chatbot.
- **Stockage Hybride** : MongoDB (Donn√©es structur√©es & M√©ta-donn√©es) + FAISS (Index vectoriel pour la recherche s√©mantique).
- **Frontend** :
  - **Application Bancaire (Next.js)** : Interface utilisateur moderne pour la consultation et la recherche.
  - **Dashboard Admin (Streamlit)** : Outil de monitoring, KPIs et configuration rapide.

```mermaid
graph TD
    User([Utilisateur]) --> Frontend[Next.js App]
    Frontend <--> API[API Gateway FastAPI]
    
    subgraph "Acquisition & Traitement"
        Sources(Sources Web/PDF) --> Scrapers[Scraping Services]
        Scrapers --> Cleaning[Nettoyage & Normalisation]
        Cleaning --> Enrichment[NLP: Classification & NER]
        Enrichment --> Embedding[Vectorisation]
    end
    
    subgraph "Stockage Hybride"
        Embedding --> VectorDB[(FAISS Index)]
        Enrichment --> DocDB[(MongoDB)]
    end
    
    subgraph "Services Intelligents"
        API --> Search[Moteur de Recherche Hybride]
        Search <--> VectorDB
        Search <--> DocDB
        API --> Chatbot[RAG Chatbot]
        Chatbot --> Search
        API --> Alerts[Service Alertes]
        Alerts --> Notif((Notifications))
    end
```

### 1.2 Stack Technologique
| Couche | Technologies | R√¥le |
| :--- | :--- | :--- |
| **Backend** | Python 3.10+, FastAPI, Uvicorn | API REST performante et asynchrone, WebSockets. |
| **IA / NLP** | PyTorch, Hugging Face Transformers, spaCy | Embeddings, Classification Zero-Shot, NER, R√©sum√© abstractif. |
| **Scraping** | Playwright, httpx, BeautifulSoup4, pdfplumber | Extraction robuste (sites dynamiques JS, PDF, HTML statique). |
| **Database** | MongoDB (Motor async driver) | Stockage flexible des documents enrichis, logs d'audit, utilisateurs. |
| **Vector Search** | FAISS, sentence-transformers | Recherche par similarit√© s√©mantique haute performance. |
| **Reranking** | Cross-Encoder (MS MARCO) | Am√©lioration de la pertinence des r√©sultats de recherche. |
| **Frontend App** | Next.js 14, React, TailwindCSS, Shadcn UI | Interface utilisateur r√©active et esth√©tique. |
| **Dashboard** | Streamlit, Plotly | Visualisation rapide des donn√©es et administration. |
| **DevOps** | Docker, Docker Compose | Conteneurisation et orchestration locale. |
| **Alerting** | Microsoft Graph API (Outlook), WebSockets | Notifications temps r√©el et emails. |

---

## üìÇ 2. Structure du Projet & R√¥le des Dossiers

Le projet suit une **architecture hexagonale simplifi√©e** (Ports & Adapters) o√π la logique m√©tier est d√©coupl√©e des interfaces (API, CLI, UI).

### `app/` (C≈ìur de l'application)

#### `app/backend/` - Interface API
Contient la logique d'exposition des services via HTTP et WebSocket.
- **R√¥le** : Point d'entr√©e pour le frontend Next.js et gestion des requ√™tes clients.
- **Fichiers cl√©s** :
  - `api.py` : D√©finition des endpoints REST, gestion du cycle de vie (startup/shutdown), injection de d√©pendances.
  - `auth.py` : Gestion de l'authentification JWT (cr√©ation de tokens, v√©rification, hachage de mots de passe).
  - `schemas.py` : Mod√®les Pydantic pour la validation stricte des donn√©es (Request/Response).

#### `app/scraping/` - Module d'Acquisition
Responsable de la collecte de donn√©es depuis des sources externes.
- **R√¥le** : Explorer le web, contourner les protections, extraire le contenu utile.
- **Fichiers cl√©s** :
  - `orchestrator.py` : Chef d'orchestre asynchrone qui g√®re les files d'attente de scraping et l'appel aux mod√®les IA.
  - `institutional_scraper.py` : Scraper pour sites institutionnels standards (requ√™tes HTTP simples).
  - `browser_scraper.py` : Scraper utilisant un navigateur r√©el (Playwright) pour les sites complexes (JS, SPA).
  - `pdf_service.py` : Extraction de texte depuis des fichiers PDF (Rapports, Circulaires).
  - `sources_registry.py` : Configuration centralis√©e des sources (URLs, s√©lecteurs CSS, type de scraper).

#### `app/nlp/` - Intelligence Artificielle (Traitement)
Contient toute la logique de traitement linguistique.
- **R√¥le** : Nettoyer, comprendre et enrichir les donn√©es brutes.
- **Fichiers cl√©s** :
  - `banking_nlp.py` : Service principal int√©grant les pipelines Transformers (Classification, NER, R√©sum√©).
  - `cleaning.py` : Nettoyage du texte, d√©tection de langue, normalisation des dates.
  - `embeddings.py` : Conversion de texte en vecteurs (Semantic Embeddings).
  - `reranking.py` : R√©-ordonnancement des r√©sultats de recherche pour am√©liorer la pr√©cision.

#### `app/rag/` - Moteur RAG & Chatbot
Impl√©mente la logique de "Retrieval Augmented Generation".
- **R√¥le** : Permettre au syst√®me de r√©pondre √† des questions en utilisant sa propre base de connaissance.
- **Fichiers cl√©s** :
  - `pipeline.py` : Pipeline complet : Indexation (Chunking -> Embedding -> FAISS) et R√©cup√©ration (Query -> Search -> Rerank).
  - `chatbot.py` : Logique conversationnelle, gestion du contexte et citation des sources.
  - `chunking.py` : D√©coupage intelligent des textes pour l'indexation vectorielle (via spaCy).
  - `vector_store.py` : Abstraction de l'index FAISS (ajout, recherche, persistance).

#### `app/storage/` - Persistence des Donn√©es
Couche d'acc√®s aux donn√©es (DAO / Repository pattern).
- **R√¥le** : Abstraire les interactions avec la base de donn√©es (MongoDB) et les logs.
- **Fichiers cl√©s** :
  - `mongo_store.py` : Gestionnaires CRUD asynchrones pour Documents, Sources, Utilisateurs, Alertes.
  - `rag_storage.py` : Service hybride g√©rant √† la fois le stockage Mongo (contenu) et FAISS (vecteurs).
  - `audit_log.py` : Syst√®me de journalisation d'audit immuable pour la conformit√©.

#### `app/alerts/` - Syst√®me de Notification
G√®re la diffusion de l'information.
- **R√¥le** : Informer les utilisateurs des nouvelles donn√©es pertinentes.
- **Fichiers cl√©s** :
  - `alerts_service.py` : Logique m√©tier pour d√©cider quand et qui alerter (r√®gles de priorit√©).
  - `outlook_connector.py` : Int√©gration avec Microsoft Graph pour l'envoi d'emails professionnels.

#### `app/search/` - Moteur de Recherche
Logique unifi√©e de recherche.
- **Fichiers cl√©s** :
  - `semantic_search.py` : Moteur combinant recherche vectorielle (sens) et recherche par mots-cl√©s (pr√©cision). Impl√©mente la "Recherche Hybride".

#### `app/config/` - Configuration
- **Fichiers cl√©s** :
  - `settings.py` : Variables d'environnement, constantes globales.
  - `security.py` : Param√®tres de s√©curit√© (whitelist domaines, rate limiting).
  - `logging_config.py` : Configuration centralis√©e des logs applicatifs.

#### `app/dashboard/` - Frontend Admin (Legacy/Internal)
Application Streamlit pour l'administration rapide.
- **R√¥le** : Visualisation des KPIs, debug des listings, test manuel du scraping.

#### `app/banking-intelligence-platform/` - Frontend Utilisateur (Production)
Application Next.js compl√®te.
- **Structure** :
  - `app/` : Pages de l'application (Router App).
  - `components/` : Composants UI r√©utilisables (bas√©s sur Shadcn UI).
  - `lib/api.ts` : Client API pour communiquer avec le backend FastAPI.

---

## üåä 3. Flux de Donn√©es (Data Flow)

### 3.1 Pipeline d'Acquisition (ETL + AI)
1.  **Trigger** : Lancement manuel ou planifi√© (`run_full_scraping.py` ou API).
2.  **Scraping** : L'orchestrateur d√©l√®gue √† `InstitutionalScraper` ou `BrowserScraper` selon la source.
3.  **Extraction** : Le HTML ou PDF est converti en texte brut (`RawTextDocument`).
4.  **Nettoyage** : `TextCleaner` retire le bruit, normalise les dates, d√©tecte la langue.
5.  **Enrichissement IA** :
    - Classification Zero-Shot (Th√©matique bancaire).
    - NER (Extraction Entit√©s : Organismes, Personnes).
    - R√©sum√© (Abstractif via Transformers).
6.  **Stockage** :
    - Document enrichi -> MongoDB (`enriched_documents`).
    - Vecteurs (Embeddings) & Metadata -> FAISS Index (`vector_store/`).
7.  **Alerting** : Si le document est prioritaire -> Notification WebSocket + Email Outlook.

### 3.2 Flux de Recherche (RAG Hybrid)
1.  **Utilisateur** : Pose une question via l'interface Next.js.
2.  **Moteur de Recherche** :
    - **Branche Vectorielle** : `Question` -> Embedding -> Recherche FAISS (Top K).
    - **Branche Lexicale** : `Question` -> Recherche Texte MongoDB (Top K).
3.  **Fusion & Reranking** : Les r√©sultats sont fusionn√©s, puis un Cross-Encoder r√©√©value la pertinence de chaque passage par rapport √† la question.
4.  **R√©ponse** :
    - **Mode Recherche** : Retourne la liste des documents tri√©s.
    - **Mode Chat** : Le contexte (passages) est envoy√© √† un mod√®le de g√©n√©ration pour synth√©tiser une r√©ponse en langage naturel.

---

## üõ†Ô∏è 4. Choix Techniques & Bonnes Pratiques

### 4.1 Asynchronisme & Performance
Pour g√©rer le scraping massif et les requ√™tes concurrentes, le projet utilise intensivement `asyncio` (Python) et `AsyncIOMotorClient` (MongoDB). Cela permet de ne pas bloquer le thread principal pendant les I/O r√©seau ou disque.
- *Justification* : Python est mono-thread√© par d√©faut ; l'async est crucial pour la scalabilit√© d'un crawler.

### 4.2 Architecture RAG Hybride
Le choix d'impl√©menter une recherche hybride (Vecteurs + Mots-cl√©s) avec une √©tape de **Reranking** est un standard de l'industrie pour augmenter la pr√©cision (Precision @k).
- *Justification* : La recherche vectorielle comprend le sens mais peut manquer des termes exacts (ex: acronymes bancaires sp√©cifiques). La recherche par mots-cl√©s compense cela.

### 4.3 Modularit√© & Design Patterns
- **Factory Pattern** : Utilis√© dans les scrapers pour instancier le bon type de scraper selon la config.
- **Singleton** : Utilis√© pour les connexions lourdes (DB, Mod√®les IA) afin d'√©conomiser la RAM.
- **Dependency Injection** : Utilis√© dans FastAPI (`Depends`) pour faciliter les tests et le d√©couplage.

### 4.4 S√©curit√© & Conformit√©
- **Audit Logs** : Chaque action critique (scraping, alerte, login) est loggu√©e dans une collection immuable (`audit_trail`).
- **Sanitization** : Nettoyage des entr√©es utilisateurs et des donn√©es scrapp√©es pour √©viter les injections XSS/NoSQL.
- **Contr√¥le d'acc√®s** : RBAC simplifi√© (Admin vs Analyste) via JWT.

### 4.5 Robustesse du Scraping
L'utilisation combin√©e de `httpx` (rapide) et `Playwright` (puissant) permet de couvrir 99% des cas d'usage web.
Le scraper g√®re les retries, le respect du `robots.txt` (via `time.sleep` et User-Agent), et les erreurs SSL/Timeout.

---

## üöÄ 5. Guide de D√©marrage Rapide

### Pr√©requis
- Python 3.10+
- Node.js 18+
- MongoDB (local ou distant)

### Installation
1.  **Backend** :
    ```bash
    pip install -r requirements.txt
    python -m spacy download fr_core_news_md
    uvicorn run_api:app --reload
    ```
2.  **Frontend** :
    ```bash
    cd app/banking-intelligence-platform
    npm install
    npm run dev
    ```

### Scripts Utiles
- `python run_full_scraping.py` : Lance une campagne de collecte sur toutes les sources.
- `python init_db.py` : Initialise la base de donn√©es et cr√©e le premier utilisateur admin.
- `python run_dashboard.py` : Lance le dashboard Streamlit d'administration.
